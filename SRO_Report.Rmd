---
title: 'Self Regulation Ontology Retest Data Report'
output:
html_document:
toc: yes
toc_float: yes
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(lme4)
library(GGally)
library(jsonlite)
library(lavaan)
library(semTools)
library(psych)
library(GPArotation)
library(rmarkdown)
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
render_this <- function(){rmarkdown::render('SRO_Report.Rmd', html_notebook(toc = T, toc_float = T))}
options(digits = 4)
```

# Introduction

# Methods

## Loading and matching datasets

This report uses the variables that were designated as "meaningful" before. This is not the smallest subset where certain variables are dropped because they are correlated with other variables (within a task) and includes both accuracies as well as both kinds of DDM variables (EZ and HDDM). It will not include variables that were considered not of theoretical interest in the analyses of time 1 data. The variables that are not included will be listed for reference as well.

### Load time 1 data
```{r}
test_data <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/meaningful_variables.csv')

test_data2 <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/meaningful_variables_noDDM.csv')

test_data3 <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/meaningful_variables_EZ.csv')

test_data <- merge(test_data, test_data2)
test_data <- merge(test_data, test_data3)
rm(test_data2, test_data3)
```

For reference here are the variables that are **not** included because they were not of theoretical interest in factor structure analyses of this data so far.

```{r}
test_data2 <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/variables_exhaustive.csv')

test_data2$X <- as.character(test_data2$X)

names(test_data2)[1] <- 'sub_id'

df <- data.frame(names(test_data2)[which(names(test_data2) %in% names(test_data) == FALSE)])
names(df) = c('vars')

df
```

```{r echo=FALSE}
rm(test_data2, df)
```

### Load time 2 data 
```{r}
retest_data <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/meaningful_variables.csv')

retest_data2 <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/meaningful_variables_noDDM.csv')

retest_data3 <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/meaningful_variables_EZ.csv')

retest_data <- merge(retest_data, retest_data2)
retest_data <- merge(retest_data, retest_data3)
rm(retest_data2, retest_data3)
```

Extract retest participants from test data

```{r}
#Process sub_id columns in the data dataframes
retest_data$X <- as.character(retest_data$X)
test_data$X <- as.character(test_data$X)

names(retest_data)[1] <- 'sub_id'
names(test_data)[1] <- 'sub_id'

retest_data <- retest_data[retest_data$sub_id %in% test_data$sub_id,]
```

### Clean t1 data

The cleaning functions here are translated from the python pipeline to mimick the same procedure.

The cleaning procedures include two steps:  
1. removing outliers for each variables where outliers are defined as those who are greater than 2.5 IQR from median  
2. Log transforming variables with skew. In cleaning T1 data for the `meaningful_variables_clean.csv` variables for which skew could not be removed successfully were dropped. **This step is excluded here. Variables that are not successfully transformed will be listed but not dropped.**

```{r}
remove_outliers = function(data_column, quantile_range = 2.5){
  
  q_25 = quantile(data_column, na.rm=T)[2]
  q_50 = quantile(data_column, na.rm=T)[3]
  q_75 = quantile(data_column, na.rm=T)[4]
  
  lowlimit = q_50 - quantile_range*(q_75 - q_25)
  highlimit = q_50 + quantile_range*(q_75 - q_25)
  
  data_column = ifelse(data_column<lowlimit, NA, ifelse(data_column>highlimit, NA, data_column))
  
  return(data_column)
}

"%w/o%" <- function(x, y) x[!x %in% y]

neg_log <- function(column){
  col_max = max(column, na.rm=T)
  column = col_max+1-column
  return(log(column))
}

transform_remove_skew = function(data, columns, threshold = 1, drop=FALSE){
  
  tmp = as.data.frame(apply(data[,columns],2,skew))
  names(tmp) = c("skew")
  tmp$dv = row.names(tmp)
  tmp = tmp %>% 
    filter(abs(skew)>threshold)
  
  skewed_variables = tmp$dv
  skew_subset = data[, skewed_variables]
  positive_subset = data[,tmp$dv[tmp$skew>0]]
  negative_subset = data[,tmp$dv[tmp$skew<0]]
  
  # transform variables
  # log transform for positive skew
  positive_subset = log(positive_subset)
  successful_transforms = as.data.frame(apply(positive_subset, 2, skew))
  names(successful_transforms) = c('skew')
  successful_transforms$dv = row.names(successful_transforms)
  successful_transforms = successful_transforms %>% filter(abs(skew)<threshold)
  successful_transforms = successful_transforms$dv
  successful_transforms = positive_subset[,successful_transforms]
  dropped_vars = names(positive_subset) %w/o% names(successful_transforms)
  
  cat(rep('*', 40))
  cat('\n')
  cat(paste0(length(names(positive_subset)) ,' data positively skewed data were transformed:'))
  cat('\n')
  cat(names(positive_subset), sep = '\n')
  cat(rep('*', 40))
  cat('\n')
  
  # replace transformed variables
  data = data[,-c(which(names(data) %in% names(positive_subset)))]
  
  if(drop == TRUE){
    names(successful_transforms) = paste0(names(successful_transforms), '.logTr')
    cat(rep('*', 40))
    cat('\n')
    cat(paste0('Dropping ', length(dropped_vars) ,' positively skewed data that could not be transformed successfully:'))
    cat('\n')
    cat(dropped_vars, sep = '\n')
    cat(rep('*', 40))
    cat('\n')
    data = cbind(data, successful_transforms)
  }
  else{
    names(positive_subset) = paste0(names(positive_subset), '.logTr')
    cat(rep('*', 40))
    cat('\n')
    cat(paste0(length(dropped_vars) ,' positively skewed data could not be transformed successfully:'))
    cat('\n')
    cat(dropped_vars, sep = '\n')
    cat(rep('*', 40))
    cat('\n')
    data = cbind(data, positive_subset)
  }
  
  
  # reflected log transform for negative skew      
  negative_subset = as.data.frame(apply(negative_subset, 2, neg_log))
  successful_transforms = as.data.frame(apply(negative_subset, 2, skew))
  names(successful_transforms) = c('skew')
  successful_transforms$dv = row.names(successful_transforms)
  successful_transforms = successful_transforms %>% filter(abs(skew)<1)
  successful_transforms = successful_transforms$dv
  successful_transforms = negative_subset[,successful_transforms]
  dropped_vars = names(negative_subset) %w/o% names(successful_transforms)
  
  cat(rep('*', 40))
  cat('\n')
  cat(paste0(length(names(negative_subset)) ,' data negatively skewed data were transformed:'))
  cat('\n')
  cat(names(negative_subset), sep = '\n')
  cat(rep('*', 40))
  cat('\n')
  
  # replace transformed variables
  data = data[,-c(which(names(data) %in% names(negative_subset)))]
  if(drop == TRUE){
    names(successful_transforms) = paste0(names(successful_transforms), '.ReflogTr')
    cat(rep('*', 40))
    cat('\n')
    cat(paste0('Dropping ', length(dropped_vars) ,' negatively skewed data that could not be transformed successfully:'))
    cat('\n')
    cat(dropped_vars, sep = '\n')
    cat(rep('*', 40))
    cat('\n')
    data = cbind(data, successful_transforms)
  }
  else{
    names(negative_subset) = paste0(names(negative_subset), '.ReflogTr')
    cat(rep('*', 40))
    cat('\n')
    cat(paste0(length(dropped_vars) ,' negatively skewed data could not be transformed successfully:'))
    cat('\n')
    cat(dropped_vars, sep = '\n')
    cat(rep('*', 40))
    cat('\n')
    data = cbind(data, negative_subset)
  }
  
  return(data)
}
```

Clean test data on full sample without dropping any columns. Columns that are not transformed successfully are listed.

```{r}
numeric_cols = c()

for(i in 1:length(names(test_data))){
  if(is.numeric(test_data[,i])){
    numeric_cols <- c(numeric_cols, names(test_data)[i])
  }
}

clean_test_data = cbind(sub_id = test_data$sub_id, as.data.frame(apply(test_data[, -which(names(test_data) %in% c("sub_id"))], 2, remove_outliers)))

clean_test_data = transform_remove_skew(clean_test_data, numeric_cols)
```

```{r echo=FALSE}
rm(i)
```

### Clean t2 data

Instead of applying the same functions applied to t1 data we check which variables are transformed in what way and transform the t2 data the same way.

**Question: Should I be removing outliers from the retest data? Or keep them if they were within the ranges in the test data even if they aren't in the retest data. Right now I'm removing them depending on t2 distributions**

Remove outliers from retest data the way they have been from test data
```{r}
clean_retest_data = cbind(sub_id = retest_data$sub_id, as.data.frame(apply(retest_data[, -which(names(retest_data) %in% c("sub_id"))], 2, remove_outliers)))
```

Get list of transformed variables and the sign of their skew
```{r}
logTr_vars = data.frame(grep('logTr', names(clean_test_data), value=T))
names(logTr_vars) = c('var')
logTr_vars$sign = ifelse(grepl(".ReflogTr",logTr_vars$var), 'negative', 'positive')
logTr_vars$var = gsub(".logTr|.ReflogTr", "", logTr_vars$var)
```

Transform the t2 columns the same way t1 columns were transformed.

```{r}
for(i in 1:length(names(clean_retest_data))){
  tmp_col = names(clean_retest_data)[i]
  if(tmp_col %in% logTr_vars$var){
    sign = logTr_vars$sign[which(tmp_col == logTr_vars$var)]
      if(sign == 'positive'){
        clean_retest_data[,tmp_col] = log(clean_retest_data[,tmp_col])
        names(clean_retest_data)[which(names(clean_retest_data) == tmp_col)] = paste0(tmp_col, '.logTr')
        cat(paste0(tmp_col ,' was positively skewed and transformed.'))
        cat('\n')
      }
      else if(sign == 'negative'){
        clean_retest_data[,tmp_col] = neg_log(clean_retest_data[,tmp_col])
        names(clean_retest_data)[which(names(clean_retest_data) == tmp_col)] = paste0(tmp_col, '.ReflogTr')
        cat(paste0(tmp_col ,' was negatively skewed and transformed.'))
        cat('\n')
      }
    }
}
```

```{r echo = FALSE}
rm(i, sign, tmp_col)
```

Check transformations are correct
```{r}
retest_logTr_vars = data.frame(grep('logTr', names(clean_retest_data), value=T))
names(retest_logTr_vars) = c('var')
retest_logTr_vars$sign = ifelse(grepl(".ReflogTr",retest_logTr_vars$var), 'negative', 'positive')
retest_logTr_vars$var = gsub(".logTr|.ReflogTr", "", retest_logTr_vars$var)
retest_logTr_vars = retest_logTr_vars %>% arrange(var)
logTr_vars = logTr_vars %>% arrange(var)
retest_logTr_vars == logTr_vars
```


```{r echo=F}
rm(logTr_vars, retest_logTr_vars)
```

Switch df names

```{r}
raw_retest_data = retest_data
raw_test_data = test_data
test_data = clean_test_data
retest_data = clean_retest_data
rm(clean_test_data, clean_retest_data)
```

### Extract t-1 data for t-2 subjects
```{r}
retest_subs_test_data <- test_data[test_data$sub_id %in% retest_data$sub_id,]

rest_subs_test_data <- test_data[test_data$sub_id %in% retest_data$sub_id == FALSE,]

#Arrange datasets of same size by sub_id
retest_data = retest_data %>% arrange(sub_id)
retest_subs_test_data = retest_subs_test_data %>% arrange(sub_id)

#CHECK IF EVERYTHING IS ORDERED RIGHT
as.character(retest_subs_test_data$sub_id) == as.character(retest_data$sub_id)
```

# Results

## Correlations for all cleaned meaningful variables
Spearman only

```{r}
numeric_cols = c()

for(i in 1:length(names(test_data))){
  if(is.numeric(test_data[,i])){
    numeric_cols <- c(numeric_cols, names(test_data)[i])
  }
}

cor_df <- data.frame(spearman = rep(NA, length(numeric_cols)))

row.names(cor_df) <- numeric_cols

for(i in 1:length(numeric_cols)){
  cor_df[numeric_cols[i], 'spearman'] <- cor(retest_data[,numeric_cols[i]],retest_subs_test_data[,numeric_cols[i]], method = 'spearman', use = "pairwise.complete.obs")
}
```

Distribution of Spearman correlations
```{r warning=FALSE, message=FALSE}
cor_df %>%
  ggplot(aes(spearman))+
  geom_histogram()+
  theme_bw()+
  ggtitle('Distribution of Spearman correlations for cleaned meaningful variables')
```

Add column to tasks vs. surveys in correlation table

```{r}
cor_df$dv = row.names(cor_df)
row.names(cor_df) = seq(1:nrow(cor_df))
cor_df$task = 'task'
cor_df[grep('survey', cor_df$dv), 'task'] = 'survey'
```

### Distributions of correlations by task vs. survey

Survey reliabilities are noticably higher than task reliabilities.
```{r warning=FALSE, message=FALSE}
cor_df %>%
  ggplot(aes(spearman))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(~task)
```

Mean reliability and the number of variables for both the surveys and the tasks
```{r}
cor_df %>%
  group_by(task) %>%
  summarise(mean_spearman = mean(spearman),
            num_vars = n())
```

#### Rank order of correlations 

##### For tasks
```{r}
cor_df %>%
  filter(task == 'task') %>%
  select(dv, spearman) %>%
  arrange(-spearman)
```

##### For surveys

- Demographics are excluded from this list of variables.  
- Holt and Laury test-retest is the worst for *surveys*. But note that this is not a survey that has been studied extensively psychometrically like others. This is more similar to out tasks (one that is used more often by economists). In previous data I have worked retest reliablities for this task was ~.35 so the results here are in line with this.  
- Otherwise the lowest survey reliabilities are 0.5.
```{r}
cor_df %>%
  filter(task == 'survey') %>%
  select(dv, spearman) %>%
  arrange(-spearman)
```

## ICC for all cleaned meaningful variables

```{r}
tmp = data.frame(persons=c(1,2,3,4,5,6),
                 rater1=c(9,6,8,7,10,6),
                 rater2=c(2,1,4,1,5,2),
                 rater3=c(5,3,6,2,6,4),
                 rater4=c(8,2,8,6,9,7))

ICC(tmp%>%select(-persons))

tmp = tmp %>% gather(rater,score,-persons)
tmp
summary(aov(score ~ rater+Error(factor(persons)), tmp))
```


```{r}
match_t1_t2 <- function(dv_var, t1_df = test_data, t2_df = retest_data, merge_var = 'sub_id'){
  df = merge(t1_df[,c(merge_var, dv_var)], t2_df[,c(merge_var, dv_var)], by = merge_var)
  df = df %>% 
    na.omit()%>%
    gather(time, score, -sub_id) %>%
    separate(time, c("dv","drop","time"), sep="[.]") %>%
    select(-drop)%>%
    mutate(time=ifelse(time=="x",1,2))
  return(df)
}

tmp = match_t1_t2("adaptive_n_back.mean_load") 
summary(aov(score~Error(sub_id)+time,tmp))
(0.692-((0.876*1+0.092*133)/134))/(0.692 + ((2-1)*((0.876*1+0.092*133)/134))) #ICC(1,1) ?
(0.692-0.092)/(0.692+ ((2-1)*0.092)+ ((2*(0.876-0.092))/134)) #ICC(2,1)
(0.692-0.092)/(0.692+((2-1)*0.092)) #ICC(3,1)
(0.692-((0.876*1+0.092*133)/134))/(0.692) #ICC(1,k)
(0.692-0.092)/(0.692+((2*(0.876-0.092))/134)) #ICC(2,k)
(0.692-0.092)/(0.692) #ICC(3.k)
sqrt((92.1+0.88+12.29)/133) #sd?
sd(tmp$score) #sd?
sqrt(0.092) #sem (smaller the better)
tmp = tmp %>% spread(time, score) %>% select(-dv, -sub_id)
ICC(tmp)

tmp = match_t1_t2("bis_bas_survey.BIS") 
summary(aov(score~Error(sub_id)+time,tmp))
# summary(aov(score~Error(sub_id/time)+time,tmp)) #same thing
sqrt(0.0477)
tmp = tmp %>% spread(time, score) %>% select(-dv, -sub_id)
ICC(tmp)
```

----------------------------------------------------------------------------------------------------------------

Based on Weir 2005 ICC(3,k) does not take in to account within subject differences between two time points (fixed effect/systematic error by time). Thus, it is well approximated by Pearson's r and subject to similar criticisms. So if you're going to use this you should at least that this effect is not significant for a measure.

Conclusion based on Weir:
get ICC(3,k)
report effect size of time (p value and partial eta squared)
get SEM (sqrt(MS_error))

```{r}
icc_df <- data.frame(icc = rep(NA, length(numeric_cols)))

row.names(icc_df) <- numeric_cols

for(i in 1:length(numeric_cols)){
  icc_df[numeric_cols[i], '...'] <- ...
}
```

----------------------------------------------------------------------------------------------------------------

## Different task variable types

Mean reliabilities for different types of dependant variables

### Drift diffusion variables: raw vars vs. EZ vs. hddm

**DO THIS ON VARIABLES EXHAUSTIVE GETTING ALL RT AND ACC'S**

We should probably take a closer look at model fits instead but this could be a first step.  

The cleaned meaningful variables do not seem to include neither the EZ estimates nor accuracies
so analyses on this [here](https://htmlpreview.github.io/?https://github.com/zenkavi/SRO_Retest_Analyses/blob/master/SRO_Retest_Analyses.nb.html) are more informative. Otherwise just looking at this one might be tempted to conclude that rt's have higher reliabilities but clearly 

```{r message=FALSE, warning=FALSE, fig.height=12, fig.width=9}
cor_df%>%
  filter(grepl('EZ|hddm|_rt|_acc', dv)) %>%
  mutate(var_type = ifelse(grepl('EZ',dv), 'EZ', ifelse(grepl('hddm',dv), 'hddm', 'raw')),
         var = ifelse(grepl('_rt', dv), 'rt', ifelse(grepl('_acc', dv), 'acc', ifelse(grepl('_non_decision', dv), 'non_decision', ifelse(grepl('_thresh', dv), 'thresh', ifelse(grepl('_drift', dv), 'drift', NA)))))) %>%
  ggplot(aes(spearman))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(var_type~var)
```

```{r}
cor_df%>%
  filter(grepl('EZ|hddm|_rt|_acc', dv)) %>%
  mutate(var_type = ifelse(grepl('EZ',dv), 'EZ', ifelse(grepl('hddm',dv), 'hddm', 'raw')),
         var = ifelse(grepl('_rt', dv), 'rt', ifelse(grepl('_acc', dv), 'acc', ifelse(grepl('_non_decision', dv), 'non_decision', ifelse(grepl('_thresh', dv), 'thresh', ifelse(grepl('_drift', dv), 'drift', NA)))))) %>%
  group_by(var_type, var) %>%
  summarise(mean_spearman = mean(spearman, na.rm=T),
            sem_spear = sem(spearman),
            num_vars = sum(ifelse(is.na(spearman)==FALSE,1,0))) %>%
  arrange(var_type)
```

## Replicating the factor structure

### Confirm comparability of retest and rest sample

First do a t-test on all measures of T1 for subjects with and without retest to confirm that these two samples do not differ from each other significantly (FDR corrected)
```{r}
ttest_df = data.frame(t_stat = rep(NA, length(matching_dv_columns)),
                      p_val_raw = rep(NA, length(matching_dv_columns)))

row.names(ttest_df) <- matching_dv_columns

for(i in 1:length(matching_dv_columns)){
  ttest_df[matching_dv_columns[i], 't_stat'] <- t.test(retest_subs_test_data[,matching_dv_columns[i]], rest_subs_test_data[,matching_dv_columns[i]])$statistic
  
  ttest_df[matching_dv_columns[i], 'p_val_raw'] <- t.test(retest_subs_test_data[,matching_dv_columns[i]], rest_subs_test_data[,matching_dv_columns[i]])$p.value
}

ttest_df$dv = row.names(ttest_df)
row.names(ttest_df) = seq(1:nrow(ttest_df))
ttest_df$task = 'task'
ttest_df[grep('survey', ttest_df$dv), 'task'] = 'survey'

#correct p-values 
ttest_df$p_val_fdr = p.adjust(ttest_df$p_val_raw, method='fdr')
```

```{r echo=FALSE}
rm(i)
```

Distribution of t statistics and p values

```{r warning=FALSE, message=FALSE}
ttest_df %>%
  gather(key, value, -dv, -task) %>%
  ggplot(aes(value)) +
  geom_histogram()+
  theme_bw()+
  facet_wrap(key~task, scales='free')
```

**Which variables are significantly different between the two samples (those with and without retest data for T1)?**

13 variables have raw p values <0.05 BUT FDR corrected p values for these are not <0.05.

```{r}
ttest_df %>%
  filter(p_val_raw<0.05) %>%
  select(dv, task, t_stat, p_val_raw, p_val_fdr)
```

### Efa and Cfa

**DO ONLY ON SURVEY AND TASK DATA SEPARATELY**

Efa on the people you don't have retest on and then predict how well this holds up for people w retest on t1 and on t2.  

I haven't consulted other factor analyses that have been done on the full dataset in doing this but will be happy to adjust as necessary.

```{r}
retest_data_mngf <- retest_data[,matching_dv_columns]
retest_subs_test_mngf <- retest_subs_test_data[,matching_dv_columns]
rest_subs_test_mngf <- rest_subs_test_data[,matching_dv_columns]

#standardize all vars going in to factor analysis
rest_subs_test_mngf_z <- rest_subs_test_mngf

for(i in 1:length(rest_subs_test_mngf)){
    rest_subs_test_mngf_z[,names(rest_subs_test_mngf)[i]] = scale(rest_subs_test_mngf[,i])
}

rest_subs_test_mngf_z <- as.data.frame(rest_subs_test_mngf_z)
```

Efa on subjects from original dataset withOUT retest data (using meaningful vars only)  
Using the `psych` package I get some sort of solution but these are probably not valid given all the warnings.
```{r}
corMat <- rest_subs_test_mngf_z %>% cor(.,use = 'complete.obs')

solution <- fa(r = corMat, nfactors = 7, rotate = "oblimin", fm = "pa")
```

```{r}
print(solution$loadings, sort=T)
```

```{r}
# Pricipal Components Analysis
# entering raw data and extracting PCs 
# from the correlation matrix 
fit <- principal(rest_subs_test_mngf_z, nfactors=7, rotate="varimax")
fit

fit <- princomp(rest_subs_test_mngf_z, cor=TRUE)
summary(fit) # print variance accounted for 
loadings(fit) # pc loadings 
plot(fit,type="lines") # scree plot 
fit$scores # the principal components
biplot(fit)
```

