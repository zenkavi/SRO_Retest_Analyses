---
title: 'SRO Retest Response to Reviewers'
output:
github_document:
toc: yes
toc_float: yes
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
from_gh =FALSE

library(tidyverse)
library(jsonlite)

cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_bw())
ggplot <- function(...) ggplot2::ggplot(...) + scale_fill_manual(values=cbbPalette) + scale_color_manual(values=cbbPalette)+theme(legend.position="bottom")
```

#R1

##R1.5
>If the common assumption that threshold and non-decision time do not vary between conditions in tasks with intermixed trials is true, we could interpret the contrasts between those parameters generated from the EZ diffusion model to simply be noise. If that were the case, we shouldn't expect those contrasts to be reliable. 

TODO: 
### Are EZ threshold and non-decision time contrast estimates are >0?

Yes. The assumption that thresholds and non-decision times are the same across conditions does not hold in our data as the distributions of these parameters are systematically different than 0 for both time point.

```{r}
if(from_gh){
  eval(parse(text = getURL('https://raw.githubusercontent.com/zenkavi/SRO_DDM_Analyses/master/code/workspace_scripts/g_legend.R', ssl.verifypeer = FALSE)))
}else{
  source('/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_DDM_Analyses/code/workspace_scripts/ddm_subject_data.R')
}
```

```{r}
ez_contrast_vars = measure_labels %>%
  filter(raw_fit == "EZ" & overall_difference == "contrast") %>%
  select(dv)
```

```{r}
get_tval = function(x, val=0){
  return((mean(x, na.rm=T) - val)/(sd(x, na.rm=T)/sqrt(length(x))))
}

get_mean = function(x){
  return(mean(x, na.rm=T))
}
```

Means and and T values comparing the means to 0 for T1 data.

```{r}
test_data_522 %>%
  select(ez_contrast_vars$dv) %>%
  gather(key, value) %>%
  group_by(key) %>%
  summarise(tvals = get_tval(value), 
            means = get_mean(value))
```

Means and and T values comparing the means to 0 for T2 data.

```{r}
retest_data %>%
  select(ez_contrast_vars$dv) %>%
  gather(key, value) %>%
  group_by(key) %>%
  summarise(tvals = get_tval(value), 
            means = get_mean(value))
```

```{r}
retest_data %>%
  select(ez_contrast_vars$dv) %>%
  mutate(time = "Time 1") %>%
  bind_rows(test_data %>%
              select(ez_contrast_vars$dv) %>%
              mutate(time = "Time 2")) %>%
  gather(key, value, -time) %>%
  rename(dv = key) %>%
  left_join(measure_labels %>% select(dv, rt_acc), by = 'dv') %>%
  ggplot(aes(value))+
  geom_density(aes(group=dv, col=rt_acc), linetype="dotted")+
  geom_density(aes(col=rt_acc), size=2.5)+
  xlim(-1.5,1.5)+
  geom_vline(xintercept=0, linetype="dashed", size=1.5)+
  theme(legend.title=element_blank())+
  xlab("")+
  ylab("")+
  facet_wrap(~time)
```

```{r}
retest_data %>%
  select(ez_contrast_vars$dv) %>%
  mutate(time = "Time 1") %>%
  bind_rows(test_data %>%
              select(ez_contrast_vars$dv) %>%
              mutate(time = "Time 2")) %>%
  gather(key, value, -time) %>%
  rename(dv = key) %>%
  left_join(measure_labels %>% select(dv, rt_acc), by = 'dv') %>%
  group_by(rt_acc, time) %>%
  summarise(tvals=get_tval(value),
            means=get_mean(value))
```

### Are their reliabilities >0?

... Although the thresholds and non-decision times for contrasts are >0 they are still not reliable

```{r}
rt_ddm_vars = measure_labels %>%
  filter(overall_difference %in% c("non-contrast", "contrast")) %>%
  select(dv)

if(from_gh){
  eval(parse(text = getURL('https://raw.githubusercontent.com/zenkavi/SRO_Retest_Analyses/master/code/helper_functions/make_rel_df.R', ssl.verifypeer = FALSE)))
}else{
  source('/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_Retest_Analyses/code/helper_functions/make_rel_df.R')
}
```

*Response:* Measures do not have to be noise to be unreliable. In our data the EZ thresholds and non-decision times for contrasts are systematically different than 0 suggesting that they capture a systematic difference instead of noise. Still these measures are not reliable si
similar to differences in raw measures of response times and accuracies.

##R1.6
>In our paper, we report ICC(2,1)...

TODO: All results with ICC using ICC(2,1) instead of ICC(3,k)  
- [DONE] recode `get_retest_stats` to report all kinds of ICCs
- make new `rel_df` (with both types of ICC)
- make new `boot_df` (with both types of ICC)
- rerun MCMC models with ICC(2,1)

```{r}

```

##R1.7
>It is stated on pg. 9 that the ICC ranges from -1 to 1. Though statistical packages report negative ICCs, it is sometimes suggested that they should be treated as zero (e.g. Bartko, 1976), as a proportion of variance cannot theoretically be negative. I am unsure what the best approach is for the current purposes, but I note it for consideration. As there don't appear to be a large number of negative ICCs, I suspect it wouldn't affect the averages much. 

TODO:
- report how many negative ICC's there are
- run all analyses that include ICC's with 
  - replacing negative values with 0's 
  - removing them

```{r}

```

##R1.8
>I think it is a strength of the paper overall that the authors consider the importance of trial numbers, though I'm curious why they chose the number of trials they did for their tasks (e.g. if they came from particular studies or an average)? The role of trial numbers was also something we were interested in (see our Supplementary material D: https://link.springer.com/article/10.3758/s13428-017-0935-1#SupplementaryMaterial), and is discussed by Rouder & Haaf (2018). 

TODO:
- extract trial numbers for papers that went in to the lit search and compare to ours
- code pipeline to get reliability with k number of trials

```{r}

```

#R2

##R2.1
>The researchers were careful in their sampling procedure to try to minimize differences between participants who completed (vs. did not complete) the retest phase of the test-retest. Some simple statistical comparisons between the completers (N = 157) and non-completers/non-responders (N = 242-157 = 85) would help characterize this subset of the sample better and provide an additional data quality check. 