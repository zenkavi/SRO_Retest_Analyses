---
title: 'Self Regulation Ontology Retest Data: Initial Exploration'
output:
  html_document:
    toc: yes
    toc_float: yes
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(lme4)
library(GGally)
library(jsonlite)
library(lavaan)
library(semTools)
library(psych)
library(GPArotation)
sem <- function(x) {sd(x) / sqrt(length(x))}
options(digits = 4)
```

# Loading and matching datasets

### Load original data
```{r}
test_data <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/variables_exhaustive.csv')
```

### Load retest data
```{r}
retest_data <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/variables_exhaustive.csv')
```

Function to process lookup table
```{r}
process_lookup <- function(lookup_json){
  lookup_json <- data.frame(unlist(lookup_json))
  lookup_json$sub_id <- as.character(row.names(lookup_json))
  row.names(lookup_json) <- seq(1:nrow(lookup_json))
  names(lookup_json)[1] <- 'worker_id'
  lookup_json$worker_id <- as.character(lookup_json$worker_id)
  lookup_json$complete <- ifelse(lookup_json$worker_id == lookup_json$sub_id, 0, 1)
  lookup_json <- lookup_json %>% arrange(-complete, sub_id)
  return(lookup_json)
}
```

### Extract retest participants from test data

```{r}
test_worker_lookup <- fromJSON('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/Local/worker_lookup.json')

#Process full lookup tables for both datasets
test_worker_lookup <- process_lookup(test_worker_lookup)

#Process sub_id columns in the data dataframes
retest_data$X <- as.character(retest_data$X)
test_data$X <- as.character(test_data$X)

names(retest_data)[1] <- 'sub_id'
names(test_data)[1] <- 'sub_id'

#Trim lookup table to only include those we have data for
test_worker_lookup <- test_worker_lookup[test_worker_lookup$sub_id %in% test_data$sub_id,]

#Replace worker_id's in retest_data with original sub_id's 
correct_subids <- function(row, lookup_table){
  sub_id = row$sub_id
  if(sub_id %in% lookup_table$worker_id){
    index = which(sub_id == lookup_table$worker_id)
    sub_id = lookup_table$sub_id[index]
    row$sub_id = sub_id
  }
  return(row)
}

retest_data <- retest_data %>%
  group_by(sub_id) %>%
  do(correct_subids(.,test_worker_lookup))
```

### Checks and matching issues

Are all retest subjects in test_data? No. 
```{r}
sum(retest_data$sub_id %in% test_data$sub_id) == nrow(retest_data)
```

Who is missing?
```{r}
retest_data$sub_id[which(retest_data$sub_id %in% test_data$sub_id == FALSE)]
```

One retest participant is not in test data. Remove that subject from retest_data. This participant should not have completed the retest battery to begin with because they had failed our previous criterion on number of properly completed trials. The first HIT I posted, however, had an issue with the qualifications and before I could terminate it a handful of subjects had accepted and begun the battery so we had to let them finish. So this subject has given us good data for the retest battery but worse data for the test battery.
```{r}
retest_data <- retest_data[retest_data$sub_id %in% test_data$sub_id,]

retest_data
```

Extract test data for retest subjects
```{r}
retest_subs_test_data <- test_data[test_data$sub_id %in% retest_data$sub_id,]

rest_subs_test_data <- test_data[test_data$sub_id %in% retest_data$sub_id == FALSE,]

#Arrange datasets of same size by sub_id
retest_data = retest_data %>% arrange(sub_id)
retest_subs_test_data = retest_subs_test_data %>% arrange(sub_id)

#CHECK IF EVERYTHING IS ORDERED RIGHT
retest_subs_test_data$sub_id == retest_data$sub_id
```

Drop columns from original data that are not in retest data

Are there any columns in retest data columns that are not in the original data: No.

```{r}
names(retest_data)[names(retest_data) %in% names(retest_subs_test_data) == FALSE]
```

Test data columns that are not in the retest data: Two stage hasn't been fixed yet.

```{r}
names(retest_subs_test_data)[names(retest_subs_test_data) %in% names(retest_data) == FALSE]
```

Datasets with only matching columns

```{r}
all_columns <- unique(c(names(retest_data), names(retest_subs_test_data)))

matching_columns <- c()
for(i in 1:length(all_columns)){
  if(all_columns[i] %in% names(retest_data) & all_columns[i] %in% names(retest_subs_test_data)){
    matching_columns <- c(matching_columns, all_columns[i])
  }
}

retest_data <- retest_data[,matching_columns]
retest_subs_test_data <- retest_subs_test_data[,matching_columns]
```

# Correlations of exhaustive variables

Get list of test retest correlations for all matching (numeric) columns in the test and retest data. Note two caveats:  
**1. There are still some columns that weren't in both datasets listed above (e.g. two stage)**  
**2. Unlike meaningful variables these variables are not (yet) rid of outliers or log transformed if skewed. This will be detailed below along with its problems.**

```{r}
retest_data <- as.data.frame(retest_data)
retest_subs_test_data <- as.data.frame(retest_subs_test_data)

matching_dv_columns <- c()

for(i in 1:length(matching_columns)){
  if(is.numeric(retest_data[,matching_columns[i]]) & is.numeric(retest_subs_test_data[,matching_columns[i]])){
    matching_dv_columns <- c(matching_dv_columns, matching_columns[i])
  }
}

cor_df <- data.frame(pearson = rep(NA, length(matching_dv_columns)), spearman = rep(NA, length(matching_dv_columns)))

row.names(cor_df) <- matching_dv_columns

for(i in 1:length(matching_dv_columns)){
  cor_df[matching_dv_columns[i], 'pearson'] <- cor(retest_data[,matching_dv_columns[i]], retest_subs_test_data[,matching_dv_columns[i]], method = 'pearson', use = "pairwise.complete.obs")
  cor_df[matching_dv_columns[i], 'spearman'] <- cor(retest_data[,matching_dv_columns[i]],retest_subs_test_data[,matching_dv_columns[i]], method = 'spearman', use = "pairwise.complete.obs")
}
```

Distribution of all Pearson and Spearman correlations
```{r warning=FALSE, message=FALSE}
cor_df %>%
  gather(key, value) %>%
  ggplot(aes(value))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(~key)
```

Add column to tasks vs. surveys in correlation table

```{r}
cor_df$dv = row.names(cor_df)
row.names(cor_df) = seq(1:nrow(cor_df))
cor_df$task = 'task'
cor_df[grep('survey', cor_df$dv), 'task'] = 'survey'
```

## Distributions of correlations by task vs. survey

Survey reliabilities are noticably higher than task reliabilities.

Task reliability distributions looks alsmost bimodal. **Should figure out whether the lower ones are specific tasks or if they are certain kinds of vars (e.g. certain ddm parameters)**
```{r warning=FALSE, message=FALSE}
cor_df %>%
  gather(key, value, -dv, -task) %>%
  ggplot(aes(value))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(key~task)
```
Mean reliability and the number of variables for both the surveys and the tasks
```{r}
cor_df %>%
  group_by(task) %>%
  summarise(mean_pearson = mean(pearson),
            mean_spearman = mean(spearman),
            num_vars = n())
```

### Rank order of correlations 

#### For tasks
```{r}
cor_df %>%
  filter(task == 'task') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman)
```

#### For surveys

Note: Holt and Laury test-retest is pretty terrible. In previous data I have worked with it was ~.35. Should check to see if there is a coding error there.
```{r}
cor_df %>%
  filter(task == 'survey') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman)
```

## Distribution of each variable

The smaller meaningful_vars dataframe has been somewhat cleaned. So far in this notebook we looked at all the vars in their rawest form. Here we'll first check the distributions of all the variables and then apply the same cleaning procedure that was used for the meaningful variables to all of them. 

Note that I'm doing this for the sake of consistency for now. We might later decide that we would like to transform certain variables of interest in other ways to be able to include them in our analyses without violating the assumptions of those analyses. The current procedure checks the skewness of a column first removes the outliers defined as greater than 2.5 IQR from median then variables with skewness >1 are log transformed.

First I'll check if the variables that went in to the correlation matrix have normal distributions since at least the Pearson correlations depend on this assumption. Then everything will be cleaned the way meaningful variables was cleaned. There is a problem with this approach that I'm not sure how to deal with yet but this will be detailed below.

Function to check if the variables that went in to cor_df have normal distributions
```{r}
diff_from_normal <- function(col){
  return(shapiro.test(col)$p.value < 0.05)
}
```

Create and organize new df where distribution of vars data is stored. First for retest data only; then for test data for subjects who have retest data - restricting here since these are the subsets of data that went in to the correlation matrix. Merge and cleanup.
```{r}
dist_retest_data <- as.data.frame(apply(retest_data[,matching_dv_columns], 2, diff_from_normal))
names(dist_retest_data) <- c('retest_not_normal')
dist_retest_data$dv <- row.names(dist_retest_data)
row.names(dist_retest_data) <- seq(1:nrow(dist_retest_data))
dist_retest_data = dist_retest_data %>% select(dv, retest_not_normal)

dist_retest_subs_test_data <- as.data.frame(apply(retest_subs_test_data[,matching_dv_columns], 2, diff_from_normal))
names(dist_retest_subs_test_data) <- c('test_not_normal')
dist_retest_subs_test_data$dv <- row.names(dist_retest_subs_test_data)
row.names(dist_retest_subs_test_data) <- seq(1:nrow(dist_retest_subs_test_data))
dist_retest_subs_test_data = dist_retest_subs_test_data %>% select(dv, test_not_normal)

dist_data <- merge(dist_retest_data, dist_retest_subs_test_data, by = 'dv')

rm(dist_retest_data, dist_retest_subs_test_data)
```

Add whether dv's are tasks or survey to distribution dfs
```{r}
dist_data = cor_df %>%
  select(dv, task) %>%
  left_join(dist_data, by = 'dv')
```

What proportion is not normal?  
A large proportion of the variables are not normal for data from both sources. Larger proportions of survey data are not normal compared to task data. 
```{r}
dist_data %>%
  group_by(task) %>%
  summarise(mean_retest_not_normal  = mean(retest_not_normal),
            mean_test_not_normal = mean(test_not_normal))
```

Are the same vars that are not normally distributed in the retest data not normal in test data as well?  
List of variables that have different distributions in the two time points.
A majority of them are drift diffusion parameters (but note that these vars are overrepresented to begin with - more on them later).
```{r}
dist_data %>%
  filter(retest_not_normal != test_not_normal)
```

Apply the same cleaning procedure that was used for meaningful vars for all vars: 
```{r}
remove_outliers = function(data_column, quantile_range = 2.5){
  
  q_25 = quantile(data_column, na.rm=T)[2]
  q_50 = quantile(data_column, na.rm=T)[3]
  q_75 = quantile(data_column, na.rm=T)[4]
  
  lowlimit = q_50 - quantile_range*(q_75 - q_25)
  highlimit = q_50 + quantile_range*(q_75 - q_25)
  
  data_column = ifelse(data_column<lowlimit, NA, ifelse(data_column>highlimit, NA, data_column))
  
  return(data_column)
}

"%w/o%" <- function(x, y) x[!x %in% y]

neg_log <- function(column){
  col_max = max(column, na.rm=T)
  column = col_max+1-column
  return(log(column))
}

transform_remove_skew = function(data, columns, threshold = 1){
  
  tmp = as.data.frame(apply(data[,columns],2,skew))
  names(tmp) = c("skew")
  tmp$dv = row.names(tmp)
  tmp = tmp %>% 
    filter(abs(skew)>threshold)
  
  skewed_variables = tmp$dv
  skew_subset = data[, skewed_variables]
  positive_subset = data[,tmp$dv[tmp$skew>0]]
  negative_subset = data[,tmp$dv[tmp$skew<0]]
  
  # transform variables
  # log transform for positive skew
  positive_subset = log(positive_subset)
  successful_transforms = as.data.frame(apply(positive_subset, 2, skew))
  names(successful_transforms) = c('skew')
  successful_transforms$dv = row.names(successful_transforms)
  successful_transforms = successful_transforms %>% filter(abs(skew)<threshold)
  successful_transforms = successful_transforms$dv
  successful_transforms = positive_subset[,successful_transforms]
  dropped_vars = names(positive_subset) %w/o% names(successful_transforms)
  
  # replace transformed variables
  data = data[,-c(which(names(data) %in% names(positive_subset)))]
  names(successful_transforms) = paste0(names(successful_transforms), '.logTr')
  cat(rep('*', 40))
  cat(paste0('Dropping ', length(dropped_vars) ,' positively skewed data that could not be transformed successfully:'))
  cat(dropped_vars, sep = '\n')
  cat(rep('*', 40))
  data = cbind(data, successful_transforms)
  
  # reflected log transform for negative skew      
  negative_subset = as.data.frame(apply(negative_subset, 2, neg_log))
  successful_transforms = as.data.frame(apply(negative_subset, 2, skew))
  names(successful_transforms) = c('skew')
  successful_transforms$dv = row.names(successful_transforms)
  successful_transforms = successful_transforms %>% filter(abs(skew)<1)
  successful_transforms = successful_transforms$dv
  successful_transforms = negative_subset[,successful_transforms]
  dropped_vars = names(negative_subset) %w/o% names(successful_transforms)
  
  # replace transformed variables
  data = data[,-c(which(names(data) %in% names(negative_subset)))]
  names(successful_transforms) = paste0(names(successful_transforms), '.ReflogTr')
  cat(rep('*', 40))
  cat(paste0('Dropping ', length(dropped_vars) ,' negatively skewed data that could not be transformed successfully:'))
  cat(dropped_vars, sep = '\n')
  cat(rep('*', 40))
  data = cbind(data, successful_transforms)
  
  return(data)
}
```

Clean retest data with these rules.
```{r warning=FALSE}
clean_retest_data = as.data.frame(apply(retest_data[, matching_dv_columns], 2, remove_outliers))
clean_retest_data = transform_remove_skew(clean_retest_data, matching_dv_columns)
```

**I'm not sure what the right thing to do is regarding the cleaning of the test data for the retest subjects.** Should they be cleaned on the whole sample for the time they were collected on and then extracted (this should have an effect on outliers as well as transformations) or extracted and then cleaned. Here I am doing the latter but this seems to be resulting in more skewed variables for test data compared to the retest data so the later correlation matrix might not include all the variables we would like to look at.

```{r warning=FALSE}
clean_retest_subs_test_data = as.data.frame(apply(retest_subs_test_data[, matching_dv_columns], 2, remove_outliers))
clean_retest_subs_test_data = transform_remove_skew(retest_subs_test_data, matching_dv_columns)
```

## Correlations on cleaned variables

```{r}
clean_all_columns <- unique(c(names(clean_retest_data), names(clean_retest_subs_test_data)))

clean_matching_columns <- c()
for(i in 1:length(clean_all_columns)){
  if(clean_all_columns[i] %in% names(clean_retest_data) & clean_all_columns[i] %in% names(clean_retest_subs_test_data)){
    clean_matching_columns <- c(clean_matching_columns, clean_all_columns[i])
  }
}

clean_retest_data <- clean_retest_data[,clean_matching_columns]
clean_retest_subs_test_data <- clean_retest_subs_test_data[,clean_matching_columns]

clean_matching_dv_columns <- c()

for(i in 1:length(clean_matching_columns)){
  if(is.numeric(clean_retest_data[,clean_matching_columns[i]]) & is.numeric(clean_retest_subs_test_data[,clean_matching_columns[i]])){
    clean_matching_dv_columns <- c(clean_matching_dv_columns, clean_matching_columns[i])
  }
}

clean_cor_df <- data.frame(pearson = rep(NA, length(clean_matching_dv_columns)), spearman = rep(NA, length(clean_matching_dv_columns)))

row.names(clean_cor_df) <- clean_matching_dv_columns

for(i in 1:length(clean_matching_dv_columns)){
  clean_cor_df[clean_matching_dv_columns[i], 'pearson'] <- cor(clean_retest_data[,clean_matching_dv_columns[i]], clean_retest_subs_test_data[,clean_matching_dv_columns[i]], method = 'pearson', use = "pairwise.complete.obs")
  clean_cor_df[clean_matching_dv_columns[i], 'spearman'] <- cor(clean_retest_data[,clean_matching_dv_columns[i]],clean_retest_subs_test_data[,clean_matching_dv_columns[i]], method = 'spearman', use = "pairwise.complete.obs")
}
```

```{r}
clean_cor_df %>%
  gather(key, value) %>%
  ggplot(aes(value))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(~key)
```

```{r}
clean_cor_df$dv = row.names(clean_cor_df)
row.names(clean_cor_df) = seq(1:nrow(clean_cor_df))
clean_cor_df$task = 'task'
clean_cor_df[grep('survey', clean_cor_df$dv), 'task'] = 'survey'
```

```{r}
clean_cor_df %>%
  gather(key, value, -dv, -task) %>%
  ggplot(aes(value))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(key~task)
```

This cleaning led to a slight change in the mean reliabilities but a lot of dropped variables.

```{r}
clean_cor_df %>%
  group_by(task) %>%
  summarise(mean_pearson = mean(pearson),
            mean_spearman = mean(spearman),
            num_vars = n())
```

--------------------------------

Drift diffusion variables: raw vars vs. EZ vs. hddm

Mean reliabilities for different kinds of variables (e.g. drift rates and NDs; separately for EZ and HDDM; subtraction vs basic variables - single vs. multiple)
```{r}
```

--------------------------------

Can you get the factor structure for the retest
step 1:Ttest on all measures of T1 for people w and without retest
```{r}

```

step2 : efa on the people you don't have retest on and then predict how well this holds up for people w retest on t1 and on t2

Data cleaning for efa
```{r eval=FALSE}
#read in only meaningful vars
meaningful_var_test <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/meaningful_variables_clean.csv')

meaningful_var_retest <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/meaningful_variables_clean.csv')

#Process sub_id columns in the data dataframes
meaningful_var_retest$X <- as.character(meaningful_var_retest$X)
meaningful_var_test$X <- as.character(meaningful_var_test$X)

names(meaningful_var_retest)[1] <- 'sub_id'
names(meaningful_var_test)[1] <- 'sub_id'

#Clean and subset dfs as before
meaningful_var_retest <- meaningful_var_retest %>%
  group_by(sub_id) %>%
  do(correct_subids(.,test_worker_lookup))

#Are all retest subjects in test_data? No. 
sum(meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id) == nrow(meaningful_var_retest)

#Who is missing?
meaningful_var_retest$sub_id[which(meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id == FALSE)]

#Remove sub w missing test data from retest data
retest_data_mngf <- meaningful_var_retest[meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id,]

#Extract test data for subs w retest data
retest_subs_test_mngf <- meaningful_var_test[meaningful_var_test$sub_id %in% meaningful_var_retest$sub_id,]

#Extract test data for subs without retest data (efa df)
rest_subs_test_mngf <- meaningful_var_test[meaningful_var_test$sub_id %in% meaningful_var_retest$sub_id == FALSE,]

#Arrange datasets of same size by sub_id
retest_data_mngf = retest_data_mngf %>% arrange(sub_id)
retest_subs_test_mngf = retest_subs_test_mngf %>% arrange(sub_id)

#CHECK IF EVERYTHING IS ORDERED RIGHT
retest_subs_test_mngf$sub_id == retest_data_mngf$sub_id
```

Checking columns for efa:
NEED TO RESOLVE SOME DIFFERENCES IN MEANINGFUL VARS BETWEEN THE TWO DATASETS
```{r eval=FALSE}
#Check columns 
names(retest_data_mngf)[names(retest_data_mngf) %in% names(retest_subs_test_mngf) == FALSE]

names(retest_subs_test_mngf)[names(retest_subs_test_mngf) %in% names(retest_data_mngf) == FALSE]

#Subset datasets with only matching columns
all_columns_mngf <- unique(c(names(retest_data_mngf), names(retest_subs_test_mngf)))

matching_columns_mngf <- c()
for(i in 1:length(all_columns_mngf)){
  if(all_columns_mngf[i] %in% names(retest_data_mngf) & all_columns_mngf[i] %in% names(retest_subs_test_mngf)){
    matching_columns_mngf <- c(matching_columns_mngf, all_columns_mngf[i])
  }
}

retest_data_mngf <- retest_data_mngf[,matching_columns_mngf]
retest_subs_test_mngf <- retest_subs_test_mngf[,matching_columns_mngf]
rest_subs_test_mngf <- rest_subs_test_mngf[,matching_columns_mngf]

#standardize all vars going in to factor analysis
rest_subs_test_mngf_z <- rest_subs_test_mngf

for(i in 1:length(rest_subs_test_mngf)){
  if(names(rest_subs_test_mngf)[i] == 'sub_id'){
    rest_subs_test_mngf_z$sub_id = rest_subs_test_mngf$sub_id
  }
  else{
    rest_subs_test_mngf_z[,names(rest_subs_test_mngf)[i]] = scale(rest_subs_test_mngf[,i])
  }
}

rest_subs_test_mngf_z <- as.data.frame(rest_subs_test_mngf_z)
```


Efa on subjects from original dataset withOUT retest data (using meaningful vars only)
```{r eval=FALSE}
unrotated <- efaUnrotate(rest_subs_test_mngf_z, nf=3, varList=names(rest_subs_test_mngf_z)[-1], estimator="mlr")

summary(unrotated, std=TRUE)
inspect(unrotated, "std")
```


```{r eval = FALSE}
corMat <- rest_subs_test_mngf_z %>% select(-sub_id) %>% cor(.,use = 'complete.obs')

solution <- fa(r = corMat, nfactors = 3, rotate = "oblimin", fm = "pa")
```

```{r eval = FALSE}
solution
```

 
Completion times/days
 
 - First data release email esp to ASU
 - Send the spreadsheet with meaningul variables + demographics
 
 
T1 comparison for people who came back vs didn't (of all that are invited)
