---
title: 'Self Regulation Ontology Retest Data: Initial Exploration'
output:
  html_notebook: default
  pdf_document: default
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(lme4)
library(GGally)
library(jsonlite)
sem <- function(x) {sd(x) / sqrt(length(x))}
options(digits = 4)
```

Load original data
```{r}
test_data <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/variables_exhaustive.csv')
```

Load retest data
```{r}
retest_data <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/variables_exhaustive.csv')
```

Function to process lookup table
```{r}
process_lookup <- function(lookup_json){
  lookup_json <- data.frame(unlist(lookup_json))
  lookup_json$sub_id <- as.character(row.names(lookup_json))
  row.names(lookup_json) <- seq(1:nrow(lookup_json))
  names(lookup_json)[1] <- 'worker_id'
  lookup_json$worker_id <- as.character(lookup_json$worker_id)
  lookup_json$complete <- ifelse(lookup_json$worker_id == lookup_json$sub_id, 0, 1)
  lookup_json <- lookup_json %>% arrange(-complete, sub_id)
  return(lookup_json)
}
```

Extract retest participants from test data

```{r}
test_worker_lookup <- fromJSON('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/Local/worker_lookup.json')

#Process full lookup tables for both datasets
test_worker_lookup <- process_lookup(test_worker_lookup)

#Process sub_id columns in the data dataframes
retest_data$X <- as.character(retest_data$X)
test_data$X <- as.character(test_data$X)

names(retest_data)[1] <- 'sub_id'
names(test_data)[1] <- 'sub_id'

#Trim lookup table to only include those we have data for
test_worker_lookup <- test_worker_lookup[test_worker_lookup$sub_id %in% test_data$sub_id,]

#Replace worker_id's in retest_data with original sub_id's 
correct_subids <- function(row, lookup_table){
  sub_id = row$sub_id
  if(sub_id %in% lookup_table$worker_id){
    index = which(sub_id == lookup_table$worker_id)
    sub_id = lookup_table$sub_id[index]
    row$sub_id = sub_id
  }
  return(row)
}

retest_data <- retest_data %>%
  group_by(sub_id) %>%
  do(correct_subids(.,test_worker_lookup))

#Are all retest subjects in test_data? No. 
sum(retest_data$sub_id %in% test_data$sub_id) == nrow(retest_data)

#Who is missing?
retest_data$sub_id[which(retest_data$sub_id %in% test_data$sub_id == FALSE)]
```

One retest participant is not in test data. Remove that subject from retest_data for now
```{r}
retest_data <- retest_data[retest_data$sub_id %in% test_data$sub_id,]

retest_data
```

Extract test data for retest subjects
```{r}
retest_subs_test_data <- test_data[test_data$sub_id %in% retest_data$sub_id,]

rest_subs_test_data <- test_data[test_data$sub_id %in% retest_data$sub_id == FALSE,]

#Arrange datasets of same size by sub_id
retest_data = retest_data %>% arrange(sub_id)
retest_subs_test_data = retest_subs_test_data %>% arrange(sub_id)

#CHECK IF EVERYTHING IS ORDERED RIGHT
retest_subs_test_data$sub_id == retest_data$sub_id
```

Drop columns from original data that are not in retest data

Are there any columns in retest data columns that are not in the original data: No.

```{r}
names(retest_data)[names(retest_data) %in% names(retest_subs_test_data) == FALSE]
```

Test data columns that are not in the retest data: Two stage hasn't been fixed yet.

```{r}
names(retest_subs_test_data)[names(retest_subs_test_data) %in% names(retest_data) == FALSE]
```

Datasets with only matching columns

```{r}
all_columns <- unique(c(names(retest_data), names(retest_subs_test_data)))

matching_columns <- c()
for(i in 1:length(all_columns)){
  if(all_columns[i] %in% names(retest_data) & all_columns[i] %in% names(retest_subs_test_data)){
    matching_columns <- c(matching_columns, all_columns[i])
  }
}

retest_data <- retest_data[,matching_columns]
retest_subs_test_data <- retest_subs_test_data[,matching_columns]
```

Get list of test retest correlations

TODO: write a nicer of getting rid of non numeric columns

```{r}
retest_data <- as.data.frame(retest_data)
retest_subs_test_data <- as.data.frame(retest_subs_test_data)
matching_dv_columns <- c()
for(i in 1:length(matching_columns)){
  if(is.numeric(retest_data[,matching_columns[i]]) & is.numeric(retest_subs_test_data[,matching_columns[i]])){
    matching_dv_columns <- c(matching_dv_columns, matching_columns[i])
  }
}

cor_df <- data.frame(pearson = rep(NA, length(matching_dv_columns)), spearman = rep(NA, length(matching_dv_columns)))

row.names(cor_df) <- matching_dv_columns

for(i in 1:length(matching_dv_columns)){
  cor_df[matching_dv_columns[i], 'pearson'] <- cor(retest_data[,matching_dv_columns[i]], retest_subs_test_data[,matching_dv_columns[i]], method = 'pearson', use = "pairwise.complete.obs")
  cor_df[matching_dv_columns[i], 'spearman'] <- cor(retest_data[,matching_dv_columns[i]],retest_subs_test_data[,matching_dv_columns[i]], method = 'spearman', use = "pairwise.complete.obs")
}
```

Distribution of Pearson correlations
```{r}
ggplot(cor_df, aes(pearson))+
  geom_histogram()+
  theme_bw()
```

Distribution of spearman correlations
```{r}
ggplot(cor_df, aes(spearman))+
  geom_histogram()+
  theme_bw()
```

Add column to tasks vs. surveys in correlation table

```{r}
cor_df$dv = row.names(cor_df)
row.names(cor_df) = seq(1:nrow(cor_df))
cor_df$task = 'task'
cor_df[grep('survey', cor_df$dv), 'task'] = 'survey'
```

Distributions of correlations by task vs. survey
```{r}
cor_df %>%
  gather(key, value, -dv, -task) %>%
  ggplot(aes(value))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(key~task)
```

Rank order correlations
For tasks
```{r}
cor_df %>%
  filter(task == 'task') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman)
```

Mean reliability for surveys
```{r}
cor_df %>%
  filter(task == 'task') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman) %>%
  summarise(mean_pearson = mean(pearson),
            mean_spearman = mean(spearman))
```

For surveys

Note: Holt and Laury test-retest is pretty terrible. In previous data it was ~.35. Should check to see if there is a coding error there.
```{r}
cor_df %>%
  filter(task == 'survey') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman)
```

Mean reliability for surveys
```{r}
cor_df %>%
  filter(task == 'survey') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman) %>%
  summarise(mean_pearson = mean(pearson),
            mean_spearman = mean(spearman))
```

Data cleaning for efa
```{r}
#read in only meaningful vars
meaningful_var_test <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/meaningful_variables_clean.csv')

meaningful_var_retest <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/meaningful_variables_clean.csv')

#Process sub_id columns in the data dataframes
meaningful_var_retest$X <- as.character(meaningful_var_retest$X)
meaningful_var_test$X <- as.character(meaningful_var_test$X)

names(meaningful_var_retest)[1] <- 'sub_id'
names(meaningful_var_test)[1] <- 'sub_id'

#Clean and subset dfs as before
meaningful_var_retest <- meaningful_var_retest %>%
  group_by(sub_id) %>%
  do(correct_subids(.,test_worker_lookup))

#Are all retest subjects in test_data? No. 
sum(meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id) == nrow(meaningful_var_retest)

#Who is missing?
meaningful_var_retest$sub_id[which(meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id == FALSE)]

#Remove sub w missing test data from retest data
retest_data_mngf <- meaningful_var_retest[meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id,]

#Extract test data for subs w retest data
retest_subs_test_mngf <- meaningful_var_test[meaningful_var_test$sub_id %in% meaningful_var_retest$sub_id,]

#Extract test data for subs without retest data (efa df)
rest_subs_test_mngf <- meaningful_var_test[meaningful_var_test$sub_id %in% meaningful_var_retest$sub_id == FALSE,]

#Arrange datasets of same size by sub_id
retest_data_mngf = retest_data_mngf %>% arrange(sub_id)
retest_subs_test_mngf = retest_subs_test_mngf %>% arrange(sub_id)

#CHECK IF EVERYTHING IS ORDERED RIGHT
retest_subs_test_mngf$sub_id == retest_data_mngf$sub_id
```

Checking columns for efa:
NEED TO RESOLVE SOME DIFFERENCES IN MEANINGFUL VARS BETWEEN THE TWO DATASETS
```{r}
#Check columns 
names(retest_data_mngf)[names(retest_data_mngf) %in% names(retest_subs_test_mngf) == FALSE]

names(retest_subs_test_mngf)[names(retest_subs_test_mngf) %in% names(retest_data_mngf) == FALSE]

#Subset datasets with only matching columns
all_columns_mngf <- unique(c(names(retest_data_mngf), names(retest_subs_test_mngf)))

matching_columns_mngf <- c()
for(i in 1:length(all_columns_mngf)){
  if(all_columns_mngf[i] %in% names(retest_data_mngf) & all_columns_mngf[i] %in% names(retest_subs_test_mngf)){
    matching_columns_mngf <- c(matching_columns_mngf, all_columns_mngf[i])
  }
}

retest_data_mngf <- retest_data_mngf[,matching_columns_mngf]
retest_subs_test_mngf <- retest_subs_test_mngf[,matching_columns_mngf]
rest_subs_test_mngf <- rest_subs_test_mngf[,matching_columns_mngf]

#standardize all vars going in to factor analysis
rest_subs_test_mngf_z <- rest_subs_test_mngf

for(i in 1:length(rest_subs_test_mngf)){
  if(names(rest_subs_test_mngf)[i] == 'sub_id'){
    rest_subs_test_mngf_z$sub_id = rest_subs_test_mngf$sub_id
  }
  else{
    rest_subs_test_mngf_z[,names(rest_subs_test_mngf)[i]] = scale(rest_subs_test_mngf[,i])
  }
}
```

Efa on subjects from original dataset withOUT retest data (using meaningful vars only)
```{r}
unrotated <- efaUnrotate(rest_subs_test_mngf_z, nf=3, varList=names(rest_subs_test_mngf_z)[-1], estimator="mlr")

summary(unrotated, std=TRUE)
inspect(unrotated, "std")
```


```{r}
library(psych)
corMat <- cor(rest_subs_test_mngf_z)
solution <- fa(r = corMat, nfactors = 2, rotate = "oblimin", fm = "pa")
```

Drift diffusion variables: raw vars vs. EZ vs. hddm

Mean reliabilities for different kinds of variables (e.g. drift rates and NDs; separately for EZ and HDDM; subtraction vs basic variables - single vs. multiple)
```{r}
cor_df$dv
```

Distribution of each variable
 
Completion times/days
 
 - First data release email esp to ASU
 - Send the spreadsheet with meaningul variables + demographics
 
 Can you get the factor structure for the retest
 step 1:Ttest on all measures of T1 for people w and without retest
 step2 : efa on the people you don't have retest on and then predict how well this holds up for people w retest on t1 and on t2
 
T1 comparison for people who came back vs didn't (of all that are invited)
