---
title: 'Self Regulation Ontology Retest Data: Initial Exploration'
output:
  html_notebook: default
  html_document: default
  pdf_document: default
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(lme4)
library(GGally)
library(jsonlite)
library(lavaan)
library(semTools)
library(psych)
library(GPArotation)
sem <- function(x) {sd(x) / sqrt(length(x))}
options(digits = 4)
```

Load original data
```{r}
test_data <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/variables_exhaustive.csv')
```

Load retest data
```{r}
retest_data <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/variables_exhaustive.csv')
```

Function to process lookup table
```{r}
process_lookup <- function(lookup_json){
  lookup_json <- data.frame(unlist(lookup_json))
  lookup_json$sub_id <- as.character(row.names(lookup_json))
  row.names(lookup_json) <- seq(1:nrow(lookup_json))
  names(lookup_json)[1] <- 'worker_id'
  lookup_json$worker_id <- as.character(lookup_json$worker_id)
  lookup_json$complete <- ifelse(lookup_json$worker_id == lookup_json$sub_id, 0, 1)
  lookup_json <- lookup_json %>% arrange(-complete, sub_id)
  return(lookup_json)
}
```

Extract retest participants from test data

```{r}
test_worker_lookup <- fromJSON('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/Local/worker_lookup.json')

#Process full lookup tables for both datasets
test_worker_lookup <- process_lookup(test_worker_lookup)

#Process sub_id columns in the data dataframes
retest_data$X <- as.character(retest_data$X)
test_data$X <- as.character(test_data$X)

names(retest_data)[1] <- 'sub_id'
names(test_data)[1] <- 'sub_id'

#Trim lookup table to only include those we have data for
test_worker_lookup <- test_worker_lookup[test_worker_lookup$sub_id %in% test_data$sub_id,]

#Replace worker_id's in retest_data with original sub_id's 
correct_subids <- function(row, lookup_table){
  sub_id = row$sub_id
  if(sub_id %in% lookup_table$worker_id){
    index = which(sub_id == lookup_table$worker_id)
    sub_id = lookup_table$sub_id[index]
    row$sub_id = sub_id
  }
  return(row)
}

retest_data <- retest_data %>%
  group_by(sub_id) %>%
  do(correct_subids(.,test_worker_lookup))
```

Are all retest subjects in test_data? No. 
```{r}
sum(retest_data$sub_id %in% test_data$sub_id) == nrow(retest_data)
```

Who is missing?
```{r}
retest_data$sub_id[which(retest_data$sub_id %in% test_data$sub_id == FALSE)]
```

One retest participant is not in test data. Remove that subject from retest_data for now
```{r}
retest_data <- retest_data[retest_data$sub_id %in% test_data$sub_id,]

retest_data
```

Extract test data for retest subjects
```{r}
retest_subs_test_data <- test_data[test_data$sub_id %in% retest_data$sub_id,]

rest_subs_test_data <- test_data[test_data$sub_id %in% retest_data$sub_id == FALSE,]

#Arrange datasets of same size by sub_id
retest_data = retest_data %>% arrange(sub_id)
retest_subs_test_data = retest_subs_test_data %>% arrange(sub_id)

#CHECK IF EVERYTHING IS ORDERED RIGHT
retest_subs_test_data$sub_id == retest_data$sub_id
```

Drop columns from original data that are not in retest data

Are there any columns in retest data columns that are not in the original data: No.

```{r}
names(retest_data)[names(retest_data) %in% names(retest_subs_test_data) == FALSE]
```

Test data columns that are not in the retest data: Two stage hasn't been fixed yet.

```{r}
names(retest_subs_test_data)[names(retest_subs_test_data) %in% names(retest_data) == FALSE]
```

Datasets with only matching columns

```{r}
all_columns <- unique(c(names(retest_data), names(retest_subs_test_data)))

matching_columns <- c()
for(i in 1:length(all_columns)){
  if(all_columns[i] %in% names(retest_data) & all_columns[i] %in% names(retest_subs_test_data)){
    matching_columns <- c(matching_columns, all_columns[i])
  }
}

retest_data <- retest_data[,matching_columns]
retest_subs_test_data <- retest_subs_test_data[,matching_columns]
```

Get list of test retest correlations

TODO: write a nicer of getting rid of non numeric columns

```{r}
retest_data <- as.data.frame(retest_data)
retest_subs_test_data <- as.data.frame(retest_subs_test_data)

matching_dv_columns <- c()

for(i in 1:length(matching_columns)){
  if(is.numeric(retest_data[,matching_columns[i]]) & is.numeric(retest_subs_test_data[,matching_columns[i]])){
    matching_dv_columns <- c(matching_dv_columns, matching_columns[i])
  }
}

cor_df <- data.frame(pearson = rep(NA, length(matching_dv_columns)), spearman = rep(NA, length(matching_dv_columns)))

row.names(cor_df) <- matching_dv_columns

for(i in 1:length(matching_dv_columns)){
  cor_df[matching_dv_columns[i], 'pearson'] <- cor(retest_data[,matching_dv_columns[i]], retest_subs_test_data[,matching_dv_columns[i]], method = 'pearson', use = "pairwise.complete.obs")
  cor_df[matching_dv_columns[i], 'spearman'] <- cor(retest_data[,matching_dv_columns[i]],retest_subs_test_data[,matching_dv_columns[i]], method = 'spearman', use = "pairwise.complete.obs")
}
```

Distribution of all Pearson and Spearman correlations
```{r}
cor_df %>%
  gather(key, value) %>%
  ggplot(aes(value))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(~key)
```

Add column to tasks vs. surveys in correlation table

```{r}
cor_df$dv = row.names(cor_df)
row.names(cor_df) = seq(1:nrow(cor_df))
cor_df$task = 'task'
cor_df[grep('survey', cor_df$dv), 'task'] = 'survey'
```

Distributions of correlations by task vs. survey

Survey reliabilities are noticably higher than task reliabilities.

Task reliability distributions looks alsmost bimodal. **Should figure out whether the lower ones are specific tasks or if they are certain kinds of vars (e.g. certain ddm parameters)**
```{r}
cor_df %>%
  gather(key, value, -dv, -task) %>%
  ggplot(aes(value))+
  geom_histogram()+
  theme_bw()+
  facet_wrap(key~task)
```

Rank order correlations
For tasks
```{r}
cor_df %>%
  filter(task == 'task') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman)
```

Mean reliability for tasks
```{r}
cor_df %>%
  filter(task == 'task') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman) %>%
  summarise(mean_pearson = mean(pearson),
            mean_spearman = mean(spearman),
            num_vars = n())
```

For surveys

Note: Holt and Laury test-retest is pretty terrible. In previous data it was ~.35. Should check to see if there is a coding error there.
```{r}
cor_df %>%
  filter(task == 'survey') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman)
```

Mean reliability for surveys
```{r}
cor_df %>%
  filter(task == 'survey') %>%
  select(dv, spearman, pearson) %>%
  arrange(-pearson, -spearman) %>%
  summarise(mean_pearson = mean(pearson),
            mean_spearman = mean(spearman),
            num_vars = n())
```

Distribution of each variable

Check if the variables that went in to the correlation matrix have normal distributions since at least the Pearson correlations depend on this assumption. If not transform data columns in both retest and test data and calculate a new correlation df.

Function to check if the variables that went in to cor_df have normal distributions
```{r}
diff_from_normal <- function(col){
  return(shapiro.test(col)$p.value < 0.05)
}
```

Check distributions of retest data

The smaller meaningful vars have been somewhat cleaned. So far in this notebook we looked at all the vars in their rawest form.

Create and organize new df where distribution of vars data is stored. First for retest data only; then for test data for subjects who have retest data - restricting here since these are the subsets of data that went in to the correlation matrix. Merge and cleanup
```{r}
dist_retest_data <- as.data.frame(apply(retest_data[,matching_dv_columns], 2, diff_from_normal))
names(dist_retest_data) <- c('retest_not_normal')
dist_retest_data$dv <- row.names(dist_retest_data)
row.names(dist_retest_data) <- seq(1:nrow(dist_retest_data))
dist_retest_data = dist_retest_data %>% select(dv, retest_not_normal)

dist_retest_subs_test_data <- as.data.frame(apply(retest_subs_test_data[,matching_dv_columns], 2, diff_from_normal))
names(dist_retest_subs_test_data) <- c('test_not_normal')
dist_retest_subs_test_data$dv <- row.names(dist_retest_subs_test_data)
row.names(dist_retest_subs_test_data) <- seq(1:nrow(dist_retest_subs_test_data))
dist_retest_subs_test_data = dist_retest_subs_test_data %>% select(dv, test_not_normal)

dist_data <- merge(dist_retest_data, dist_retest_subs_test_data, by = 'dv')

rm(dist_retest_data, dist_retest_subs_test_data)
```

Add whether dv's are tasks or survey to distribution dfs
```{r}
dist_data = cor_df %>%
  select(dv, task) %>%
  left_join(dist_data, by = 'dv')
```

What proportion is not normal?
A large proportion of the variables are not normal for data from both sources. Larger proportions of survey data are not normal compared to task data. 
```{r}
dist_data %>%
  group_by(task) %>%
  summarise(mean_retest_not_normal  = mean(retest_not_normal),
            mean_test_not_normal = mean(test_not_normal))
```

Are the same vars that are not normally distributed in the retest data not normal in test data as well?
List of variables that have different distributions in the two time points (shown here is whether they are normally distributed in the retest data)
A majority of them are drift diffusion parameters (but note that these vars are overrepresented to begin with - more on them later).
```{r}
dist_data %>%
  filter(retest_not_normal != test_not_normal)
```

Apply the same cleaning procedure that was used for meaningful vars for all vars:
```{r}
"%w/o%" <- function(x, y) x[!x %in% y]

transform_remove_skew = function(data, cols, threshold = 1){
  
  tmp = as.data.frame(apply(data[,columns],2,skew))
  names(tmp) = c("skew")
  tmp$dv = row.names(tmp)
  tmp = tmp %>% 
    filter(abs(skew)>threshold)
  
  skewed_variables = tmp$dv
  skew_subset = data[, skewed_variables]
  positive_subset = data[,tmp$dv[tmp$skew>0]]
  negative_subset = data[,tmp$dv[tmp$skew<0]]
  
  # transform variables
  # log transform for positive skew
  positive_subset = log(positive_subset)
  successful_transforms = as.data.frame(apply(positive_subset, 2, skew))
  names(successful_transforms) = c('skew')
  successful_transforms$dv = row.names(successful_transforms)
  successful_transforms = successful_transforms %>% filter(abs(skew)<threshold)
  successful_transforms = successful_transforms$dv
  successful_transforms = positive_subset[,successful_transforms]
  dropped_vars = names(positive_subset) %w/o% names(successful_transforms)
  
  # replace transformed variables
  data = data[,-c(which(names(data) %in% names(positive_subset)))]
  names(successful_transforms) = paste0(names(successful_transforms), '.logTr')
  print.noquote(rep('*', 40))
  print(paste0('Dropping', length(dropped_vars) ,'positively skewed data that could not be transformed successfully:')
        
        
  print('\n'.join(dropped_vars))
  print.noquote(rep('*', 40))
  data = pd.concat([data, successful_transforms], axis = 1)
}

tmp = as.data.frame(apply(retest_data[, matching_dv_columns], 2, skew))
names(tmp) = c('skew')
tmp$dv = row.names(tmp)
tmp = tmp %>%
  filter(abs(skew)>1)
positive_subset = retest_data[,tmp$dv[tmp$skew>0]]

positive_subset = log(positive_subset)
successful_transforms = as.data.frame(apply(positive_subset, 2, skew))
names(successful_transforms) = c('skew')
successful_transforms$dv = row.names(successful_transforms)
successful_transforms = successful_transforms %>% filter(abs(skew)<1)
successful_transforms = successful_transforms$dv
successful_transforms = positive_subset[,successful_transforms]
dropped_vars = names(positive_subset) %w/o% names(successful_transforms)

tmp_retest_data = retest_data
tmp_retest_data = tmp_retest_data[,-c(which(names(tmp_retest_data) %in% 
                                              names(positive_subset)))]

#transform_remove_skew(retest_data, matching_dv_columns)
```

Transform non normal vars
Transform both retest and test data if not normally distributed in either. 
Order of transformations tried: log and sqrt
```{r}
#Add columns to dist_data that will be updated
dist_data = dist_data %>%
  mutate(retest_transform = ifelse(retest_not_normal, NA, 'none'),
         test_transform = ifelse(test_not_normal, NA, 'none'))

get_transform <- function(data){
  t_data = data
  transform = 'none'
  if(diff_from_normal(data) & !is.na(diff_from_normal(data))){
    t_data = log1p(data)
    transform = 'log1p'
    if(diff_from_normal(t_data) & !is.na(diff_from_normal(t_data))){
      t_data = sqrt(data)
      transform = 'sqrt'
      if(diff_from_normal(t_data) & !is.na(diff_from_normal(t_data))){
        transform = 'failed'
      }
    }
  }
  return(transform)
}

for(i in 1:nrow(dist_data)){
  if(is.na(dist_data$retest_transform[i])){
    dist_data$retest_transform[i] = get_transform(retest_data[,dist_data$dv[i]])
  }
  if(is.na(dist_data$test_transform[i])){
    dist_data$test_transform[i] = get_transform(retest_subs_test_data[,dist_data$dv[i]])
  }
}

t_retest_data = retest_data
t_retest_subs_test_data = retest_subs_test_data


#check if normal
#if yes stop and record transformation = none
#if transform: log
#check if normal
#if yes stop and record transformation = log
#if no transform: sqrt
```

Drift diffusion variables: raw vars vs. EZ vs. hddm

Mean reliabilities for different kinds of variables (e.g. drift rates and NDs; separately for EZ and HDDM; subtraction vs basic variables - single vs. multiple)
```{r}
```

--------------------------------

Can you get the factor structure for the retest
step 1:Ttest on all measures of T1 for people w and without retest
```{r}

```

step2 : efa on the people you don't have retest on and then predict how well this holds up for people w retest on t1 and on t2

Data cleaning for efa
```{r}
#read in only meaningful vars
meaningful_var_test <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Complete_01-31-2017/meaningful_variables_clean.csv')

meaningful_var_retest <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_02-11-2017/meaningful_variables_clean.csv')

#Process sub_id columns in the data dataframes
meaningful_var_retest$X <- as.character(meaningful_var_retest$X)
meaningful_var_test$X <- as.character(meaningful_var_test$X)

names(meaningful_var_retest)[1] <- 'sub_id'
names(meaningful_var_test)[1] <- 'sub_id'

#Clean and subset dfs as before
meaningful_var_retest <- meaningful_var_retest %>%
  group_by(sub_id) %>%
  do(correct_subids(.,test_worker_lookup))

#Are all retest subjects in test_data? No. 
sum(meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id) == nrow(meaningful_var_retest)

#Who is missing?
meaningful_var_retest$sub_id[which(meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id == FALSE)]

#Remove sub w missing test data from retest data
retest_data_mngf <- meaningful_var_retest[meaningful_var_retest$sub_id %in% meaningful_var_test$sub_id,]

#Extract test data for subs w retest data
retest_subs_test_mngf <- meaningful_var_test[meaningful_var_test$sub_id %in% meaningful_var_retest$sub_id,]

#Extract test data for subs without retest data (efa df)
rest_subs_test_mngf <- meaningful_var_test[meaningful_var_test$sub_id %in% meaningful_var_retest$sub_id == FALSE,]

#Arrange datasets of same size by sub_id
retest_data_mngf = retest_data_mngf %>% arrange(sub_id)
retest_subs_test_mngf = retest_subs_test_mngf %>% arrange(sub_id)

#CHECK IF EVERYTHING IS ORDERED RIGHT
retest_subs_test_mngf$sub_id == retest_data_mngf$sub_id
```

Checking columns for efa:
NEED TO RESOLVE SOME DIFFERENCES IN MEANINGFUL VARS BETWEEN THE TWO DATASETS
```{r}
#Check columns 
names(retest_data_mngf)[names(retest_data_mngf) %in% names(retest_subs_test_mngf) == FALSE]

names(retest_subs_test_mngf)[names(retest_subs_test_mngf) %in% names(retest_data_mngf) == FALSE]

#Subset datasets with only matching columns
all_columns_mngf <- unique(c(names(retest_data_mngf), names(retest_subs_test_mngf)))

matching_columns_mngf <- c()
for(i in 1:length(all_columns_mngf)){
  if(all_columns_mngf[i] %in% names(retest_data_mngf) & all_columns_mngf[i] %in% names(retest_subs_test_mngf)){
    matching_columns_mngf <- c(matching_columns_mngf, all_columns_mngf[i])
  }
}

retest_data_mngf <- retest_data_mngf[,matching_columns_mngf]
retest_subs_test_mngf <- retest_subs_test_mngf[,matching_columns_mngf]
rest_subs_test_mngf <- rest_subs_test_mngf[,matching_columns_mngf]

#standardize all vars going in to factor analysis
rest_subs_test_mngf_z <- rest_subs_test_mngf

for(i in 1:length(rest_subs_test_mngf)){
  if(names(rest_subs_test_mngf)[i] == 'sub_id'){
    rest_subs_test_mngf_z$sub_id = rest_subs_test_mngf$sub_id
  }
  else{
    rest_subs_test_mngf_z[,names(rest_subs_test_mngf)[i]] = scale(rest_subs_test_mngf[,i])
  }
}

rest_subs_test_mngf_z <- as.data.frame(rest_subs_test_mngf_z)
```


Efa on subjects from original dataset withOUT retest data (using meaningful vars only)
```{r}
unrotated <- efaUnrotate(rest_subs_test_mngf_z, nf=3, varList=names(rest_subs_test_mngf_z)[-1], estimator="mlr")

summary(unrotated, std=TRUE)
inspect(unrotated, "std")
```


```{r}
corMat <- rest_subs_test_mngf_z %>% select(-sub_id) %>% cor(.,use = 'complete.obs')

solution <- fa(r = corMat, nfactors = 3, rotate = "oblimin", fm = "pa")
```

```{r}
solution
```

 
Completion times/days
 
 - First data release email esp to ASU
 - Send the spreadsheet with meaningul variables + demographics
 
 
T1 comparison for people who came back vs didn't (of all that are invited)
