Retest data pipeline

General:
- Begin on local repo
- Check branch and pull upstream master
- Push master to origin
- Merge master to retest_scripts branch
- Push retest_scripts to origin
- Make, add, commit all changes locally
- Push all changes to origin
- Pull on Sherlock
- Run all jobs on Sherlock
- pip install -e expfactory-analysis
- python setup.py install for selfregulation module
- SRO conda environment can be built using environment.yml in the root directory (conda env create -f environment.yml)

Download data + post process + QC
Input: Self_Regulation_Retest_Settings.txt, expfactory_token.txt, worker_lookup.json
Script: retest_download_data.py
Output: mturk_retest_data.json, retest_worker_lookup.json, retest_worker_counts.json, mturk_retest_data_extras.pkl (or .json), retest_worker_pay.json, mturk_retest_data_post.json, mturk_retest_failed_data_post.json
Run: local in case of debugging; takes a while

Save data I (pre dv calculation)
Input: mturk_retest_data_post.json
Script: retest_save_data_pre.py
Output: /Individual_Measures/, /metadata/, /references/, demographics.csv, demographics_ordinal.csv, alcohol_drugs.csv, alcohol_drugs_ordinal.csv, health.csv, health_ordinal.csv, demographic_health.csv, references/demographic_health_reference.csv, items.csv.gz, subject_x_items.csv, README.txt, metadata/alcohol_drugs.json, demographics.json, health.json
Run: Sherlock (~13 minutes)

DV creation
Input: calculate_retest_DVs.batch, Data/Retest_11-27-2017/batch_output, Data/Retest_11-27-2017/batch_output/.err, Data/Retest_11-27-2017/batch_output/.out, calculate_retest_exp_DVs.py
Script: /batch_file/retest/run_retest_exps.sh
Output: /batch_files/retest/*.model, /batch_files/retest/*.db, /batch_files/retest/*.csv, ../../Data/Retest_11-27-2017/batch_output/*_retest_DV.json, ../../Data/Retest_11-27-2017/batch_output/*_retest_DV_valence.json 
Run: On Sherlock 1 using ~/miniconda3/bin/python, on Sherlock 2 using ~/miniconda/bin/python with the SRO environment 

Post DV creation cleanup
Input: change path in concatenate_retest_DVs.py
Script: cleanup_retest.sh
Output: ../../Data/Retest_11-27-2017/batch_output/hddm_models/*.model, ../../Data/Retest_11-27-2017/batch_output/hddm_models/*.db, ../../Data/Retest_11-27-2017/batch_output/hddm_data/*_data.csv, ../../Data/Retest_11-27-2017/Local/
Run: On Sherlock from batch_files/retest

Save data II (post dv calculation)
Input: mturk_retest_DV.json, mturk_retest_DV_valence.json
Script: retest_save_data_post.py
Output: meaningful_variables.csv, meaningful_variables_EZ.csv, meaningful_variables_clean.csv, meaningful_variables_hddm.csv, meaningful_variables_imputed.csv, meaningful_variables_imputed_for_task_selection.csv, meaningful_variables_noDDM.csv, short_DV_valence.csv, short_meaningful_variables.csv, short_meaningful_variables_EZ.csv, short_meaningful_variables_clean.csv, short_meaningful_variables_hddm.csv, short_meaningful_variables_imputed.csv, short_meaningful_variables_imputed_for_task_selection.csv, short_meaningful_variables_noDDM.csv, short_subject_x_items.csv, short_taskdata.csv, short_taskdata_clean.csv, short_taskdata_imputed.csv, short_taskdata_imputed_for_task_selection.csv, short_variables_exhaustive.csv, taskdata.csv, taskdata_clean.csv, taskdata_imputed.csv, taskdata_imputed_for_task_selection.csv, variables_exhaustive.csv
Run: Sherlock (~2 mins)

Extract t1-data:
Input: extract_t1_data.R, extract_t1_data.batch, Data/Complete_11-22-2017/, Data/Retest_11-27-2017/t1_data
Script: run_extract_t1_data.sh
Output: Data/Retest_11-27-17/t1_data/*.csv
Run: Sherlock

Bootstrap 
Input: Data/Retest_11-27-17/batch_output/bootstrap_output, Data/Retest_11-27-17/batch_output/bootstrap_output/.err, Data/Retest_11-27-17/batch_output/bootstrap_output/.out, batch_scripts/retest/bootstrap_retest.R, bootstrap_scripts/retest/bootstrap_retest.batch, retest_report_vars.txt,
Script: run_bootstrap_retest.sh
Output: batch_output/bootstrap_output/*.csv, batch_output/bootstrap_output/.err/*.err, batch_output/bootstrap_output/.out/*.out 
Run: Sherlock

Bootstrap merge and cleanup
Input: batch_output/boostrap_output/*.csv
Script: concatenate_boostrap.sh
Output: Local/bootstrap_merged.csv
Run: Sherlock

Get retest_subs_test_data_post.json for DDM refits
Input:
Script:
Output:
Run:

DDM refit for original sample
Input: calculate_hddm_refits.batch, calculate_hddm_refits.py, batch_output/hddm_refits, batch_output/hddm_refits/.err, batch_output/hddm_refits/.out, retest_subs_test_data_post.json
Script: run_hddm_refits.sh 
Output: Sherlock

HDDM parameters without hierarchy
Input: Retest_11-27-2017/batch_output/hddm_flat/, Retest_11-27-2017/batch_output/hddm_flat/.out, Retest_11-27-2017/batch_output/hddm_flat/.err, calculate_hddm_flat.py, calculate_hddm_flat.batch
Script: run_hddm_flat.sh
Output: 
Run: Sherlock