Shavelson, R. J., & Webb, N. M. (1991). Generalizability theory: A primer. Sage.

General rule: increase the number of conditions of a facet reduces error induced by that facet and increases the generalizability of the measure

p 13:
"Measurements in the social sciences are characteristically used in two ways: (a) to rank order individuals (or groups); or (b) to index an individual's (or group's) absolute level of knowledge, skill, attitude, or strength of opinion"

p14:
"Like classical test theory's reliability coefficient, the generalizability coefficient reflects the proportion of variability in individual's scores that is systematic; that is, attributable to universe-score (cf. true score) variability."

Confused by the lumping of interaction and error variance: is this because I'm misunderstanding or due to lack of computational resources to separate the two?

p30:
"The estimated variance components from a generalizability study reflect the magnitude of error in generalizing from a person's score on a single item to his or her universe score (the person's average over all items in the universe). These estimated variance components are not the error in generalizing from the test score (average or sum of n_i items on the test)."

p66:
Why can't a G study just have fixed facets? Because there wouldn't be anything to generalize over?

p94:
"Classical test theory assumes strictly parallel measurement; that is, the means across items are assumed to be equal as are the variances [...] Hence in a p x i measurement, the item effect is assumed to be zero. [...] A consequence of the parallel-measurements assumption is that classical test theory is primarily a theory of individual differences; that is, it usually is concerned with the relative standing of individuals. The reliability coefficient, following this individual differences focus, is calculated only with sources of variation for persons and the residual"
