---
title: 'Closer look at DDM parameter estimates'
output:
github_document:
toc: yes
toc_float: yes
---

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(lme4)
library(GGally)
library(jsonlite)
library(psych)
library(rmarkdown)
library(psych)
library(stringr)
library(plotly)
library(jsonlite)
library(DT)
sem <- function(x) {sd(x, na.rm=T) / sqrt(length(x))}
render_this <- function(){rmarkdown::render('DDM_Report.Rmd', output_dir = '/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_Retest_Report', html_notebook(toc = T, toc_float = T, code_folding = 'hide'))}
options(scipen = 1, digits = 4)
```

How much do hddm parameters change when fitting to whole vs partial sample

Summary of absolute difference in parameter estimates.

```{r}
pre_correction <- read.csv('/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_Retest_Analyses/retest_subs_test_data_preddm_correction.csv')
post_correction <- read.csv('/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_Retest_Analyses/retest_subs_test_data.csv')

hddm_cols = grep('hddm', names(pre_correction), value =T)

pre_correction = pre_correction[,c("sub_id", hddm_cols)]
post_correction = post_correction[,c("sub_id", hddm_cols)]

pre_correction = pre_correction %>% mutate(pre_post = "pre")
post_correction = post_correction %>% mutate(pre_post = "post")

all_hddm = rbind(pre_correction, post_correction)

all_hddm %>%
  gather(key, value, -sub_id, -pre_post) %>%
  arrange(sub_id) %>%
  spread(pre_post, value) %>%
  mutate(abs_diff = pre-post) %>%
  group_by(key) %>%
  summarise(mean_abs_diff = mean(abs_diff, na.rm=T),
            median_abs_diff = median(abs_diff, na.rm=T),
            min_abs_diff = min(abs_diff, na.rm=T),
            max_abs_diff = max(abs_diff, na.rm=T),
            sem_abs_diff = sem(abs_diff)) %>%
  ggplot(aes(reorder(key, mean_abs_diff), mean_abs_diff))+
  geom_point()+
  geom_errorbar(aes(ymin = mean_abs_diff-sem_abs_diff, ymax = mean_abs_diff+sem_abs_diff), position=position_dodge(0.9), width = 0.25)+
  theme_bw()+
  geom_hline(yintercept=0, linetype='dashed', color='red')+
  ylab("Mean absolute difference after refit")+
  xlab("")+
  coord_flip()
```

Are the variables we see the changes on different due to transformation?

```{r}
raw_pre_correction <- read.csv('/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_Retest_Analyses/raw_retest_subs_test_data_preddm_correction.csv')

replace_hddm_vars = data.frame(grep('hddm', names(raw_pre_correction), value=T, perl=T))
names(replace_hddm_vars) = c('var')

raw_pre_correction = raw_pre_correction[,c("sub_id", as.character(replace_hddm_vars$var))]

hddm_fix_retest_subs_test_data = raw_pre_correction

raw_hddm_refits <- read.csv('/Users/zeynepenkavi/Documents/PoldrackLabLocal/Self_Regulation_Ontology/Data/Retest_03-21-2017/hddm_refits_exhaustive.csv')

for(i in 1:length(names(hddm_fix_retest_subs_test_data))){
  if(names(hddm_fix_retest_subs_test_data)[i] %in% replace_hddm_vars$var){
    hddm_fix_retest_subs_test_data[,names(hddm_fix_retest_subs_test_data)[i]] <- raw_hddm_refits[,names(hddm_fix_retest_subs_test_data)[i]]
  }
}

raw_post_correction <- hddm_fix_retest_subs_test_data

raw_pre_correction = raw_pre_correction %>% mutate(pre_post = "pre")
raw_post_correction = raw_post_correction %>% mutate(pre_post = "post")

raw_all_hddm = rbind(raw_pre_correction, raw_post_correction)

raw_all_hddm %>%
  gather(key, value, -sub_id, -pre_post) %>%
  arrange(sub_id) %>%
  spread(pre_post, value) %>%
  mutate(abs_diff = pre-post) %>%
  group_by(key) %>%
  summarise(mean_abs_diff = mean(abs_diff, na.rm=T),
            median_abs_diff = median(abs_diff, na.rm=T),
            min_abs_diff = min(abs_diff, na.rm=T),
            max_abs_diff = max(abs_diff, na.rm=T),
            sem_abs_diff = sem(abs_diff)) %>%
  ggplot(aes(reorder(key, mean_abs_diff), mean_abs_diff))+
  geom_point()+
  geom_errorbar(aes(ymin = mean_abs_diff-sem_abs_diff, ymax = mean_abs_diff+sem_abs_diff), position=position_dodge(0.9), width = 0.25)+
  theme_bw()+
  geom_hline(yintercept=0, linetype='dashed', color='red')+
  ylab("Mean absolute difference after refit")+
  xlab("")+
  coord_flip()
```

How do reliabilities change w sample size (refit from 50 to 150) both for EZ and hddm (gives a prescriptive recommendation on which method to use depending on sample size)

```{r}
all_ddm_sample_size <- read.csv('/Users/zeynepenkavi/Dropbox/PoldrackLab/SRO_Retest_Analyses/all_ddm_sample_size_estimates.csv')

all_ddm_sample_size  = all_ddm_sample_size %>%
  drop_na()
```


```{r eval=FALSE, echo=FALSE}
match_t1_t2 <- function(dv_var, t1_df = retest_subs_test_data, t2_df = retest_data, merge_var = 'sub_id', format = "long", sample = 'full', sample_vec){
  
  if(sample == 'full'){
   df = merge(t1_df[,c(merge_var, dv_var)], t2_df[,c(merge_var, dv_var)], by = merge_var) 
  }
  else{
    df = merge(t1_df[t1_df[,merge_var] %in% sample_vec, c(merge_var, dv_var)], t2_df[t2_df[,merge_var] %in% sample_vec, c(merge_var, dv_var)],
    by=merge_var)
  }
  
  df = df %>% 
    na.omit()%>%
    gather(dv, score, -sub_id) %>%
    mutate(time = ifelse(grepl('\\.x', dv), 1, ifelse(grepl('\\.y', dv), 2, NA))) %>%
    separate(dv, c("dv", "drop"), sep='\\.([^.]*)$') %>%
    select(-drop)
  
  
  if(format == 'wide'){
    df = df%>% spread(time, score) 
  }
  
  return(df)
}

get_spearman = function(dv_var, t1_df = retest_subs_test_data, t2_df = retest_data, merge_var = 'sub_id', sample='full', sample_vec){
  
  if(sample=='full'){
    df = match_t1_t2(dv_var, t1_df = t1_df, t2_df = t2_df, merge_var = merge_var, format='wide')
  }
  else if(sample=='bootstrap'){
    df = match_t1_t2(dv_var, t1_df = t1_df, t2_df = t2_df, merge_var = merge_var, format='wide', sample='bootstrap', sample_vec = sample_vec)
  }
  
  rho = cor(df$`1`, df$`2`, method='spearman')
  
  return(rho)
}

get_icc <- function(dv_var, t1_df = retest_subs_test_data, t2_df = retest_data, merge_var = 'sub_id', sample='full', sample_vec){
  if(sample=='full'){
    df = match_t1_t2(dv_var, t1_df = t1_df, t2_df = t2_df, merge_var = merge_var, format='wide')
  }
  else if(sample=='bootstrap'){
    df = match_t1_t2(dv_var, t1_df = t1_df, t2_df = t2_df, merge_var = merge_var, format='wide', sample='bootstrap', sample_vec = sample_vec)
  }
  
  df = df %>% select(-dv, -sub_id)
  icc = ICC(df)
  icc_3k = icc$results['Average_fixed_raters', 'ICC']
  return(icc_3k)
  }

get_eta <- function(dv_var, t1_df = retest_subs_test_data, t2_df = retest_data, merge_var = 'sub_id', sample='full', sample_vec){
  if(sample=='full'){
    df = match_t1_t2(dv_var, t1_df = t1_df, t2_df = t2_df, merge_var = merge_var)
  }
  else if(sample=='bootstrap'){
    df = match_t1_t2(dv_var, t1_df = t1_df, t2_df = t2_df, merge_var = merge_var, sample='bootstrap', sample_vec = sample_vec)
  }
  
  mod = summary(aov(score~Error(sub_id)+time, df))
  ss_time = as.data.frame(unlist(mod$`Error: Within`))['Sum Sq1',]
  ss_error = as.data.frame(unlist(mod$`Error: Within`))['Sum Sq2',]
  eta = ss_time/(ss_time+ss_error)
  return(eta)
  }

get_sem <- function(dv_var, t1_df = retest_subs_test_data, t2_df = retest_data, merge_var = 'sub_id', sample='full', sample_vec){
  if(sample=='full'){
    df = match_t1_t2(dv_var, t1_df = t1_df, t2_df = t2_df, merge_var = merge_var)
  }
  else if(sample=='bootstrap'){
    df = match_t1_t2(dv_var, t1_df = t1_df, t2_df = t2_df, merge_var = merge_var, sample='bootstrap', sample_vec = sample_vec)
  }
  mod = summary(aov(score~Error(sub_id)+time, df))
  ms_error = as.data.frame(unlist(mod$`Error: Within`))['Mean Sq2',]
  sem = sqrt(ms_error)
  return(sem)
}

sample_workers = function(N = 150, repl= TRUE, df=retest_data, worker_col = "sub_id"){
  return(sample(df[,worker_col], N, replace = repl))
}

bootstrap_relialibility = function(metric = c('icc', 'spearman', 'eta_sq', 'sem'), dv_var, N=150, t1_df, t2_df){
  tmp_sample = sample_workers(N, df = t1_df)
  out_df = data.frame(dv = dv_var)
  if('icc' %in% metric){
    out_df$icc = get_icc(dv_var, sample = 'bootstrap', sample_vec = tmp_sample, t1_df = t1_df, t2_df = t2_df)
  }
  if('spearman' %in% metric){
    out_df$spearman = get_spearman(dv_var, sample = 'bootstrap', sample_vec = tmp_sample, t1_df = t1_df, t2_df = t2_df)
  }
  if('eta_sq' %in% metric){
    out_df$eta_sq = get_eta(dv_var, sample = 'bootstrap', sample_vec = tmp_sample, t1_df = t1_df, t2_df = t2_df)
  }
  if('sem' %in% metric){
    out_df$sem = get_sem(dv_var, sample = 'bootstrap', sample_vec = tmp_sample, t1_df = t1_df, t2_df = t2_df)
  }
  return(out_df)
}

rel_n50_rep20 = replace_hddm_vars %>%
  mutate(index = 1:n()) %>%
  group_by(index) %>%
  do(plyr::rdply(20, bootstrap_relialibility(dv_var = as.character(.$var), t1_df = raw_pre_correction, t2_df = raw_retest_data, N=50))) %>%
  mutate(N = 50)

```

Turn off h of ddm and see if it makes a difference